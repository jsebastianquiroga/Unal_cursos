{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsebastianquiroga/Unal_cursos/blob/main/Analitica%20/2_Web_Scraping_en_Python_Twitter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#=========================================================================================================#\n",
        "#                  Facultad de Ciencias Económicas - Universidad Nacional de Colombia\n",
        "#                                 Analítica Cualitativa de Redes Sociales\n",
        "#                                       Análisis de Sentimientos\n",
        "#                                                             \n",
        "#=========================================================================================================#\n",
        "\n",
        "# Web Scraping in Social Media con Python\n",
        "\n",
        "En esta sesión se abordará el web scraping para una de las redes sociales con mayor tendencia a nivel mundial: Twitter\n",
        "\n",
        "### Instalación e importación de paquetes"
      ],
      "metadata": {
        "id": "gOkby_rPNL9k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzQr7j1cFb-5"
      },
      "source": [
        "### Instalación e importación de paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTG0CjisEWGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68b91c9-f006-4d15-839c-f3a259a6e96b"
      },
      "source": [
        "!pip install -q snscrape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m61.4/74.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m997.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upELTM7FEW52"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import date"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4CjmLVnFpLJ"
      },
      "source": [
        "### Variables\n",
        "Se establecen las variables a partir de las cuales se realizará el web scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRI_zQ1sEYaU"
      },
      "source": [
        "hoy = date.today()\n",
        "fecha_final = hoy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omLTd2slEbn7"
      },
      "source": [
        "termino_busqueda = None\n",
        "fecha_inicial = None"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYfif5q9Ek_S"
      },
      "source": [
        "## Número total de Tweets por términos buscados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6vi7EuFEdVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61a0b9c-817e-45b0-98e7-5c04dbff7c1e"
      },
      "source": [
        "os.system(f\"snscrape --since {fecha_inicial} twitter-search '{termino_busqueda} until:{fecha_final}' > result-tweets.txt\")\n",
        "if os.stat(\"result-tweets.txt\").st_size == 0:\n",
        "  counter = 0\n",
        "else:\n",
        "  df = pd.read_csv('result-tweets.txt', names=['link'])\n",
        "  counter = df.size\n",
        "\n",
        "print('Número de Tweets : '+ str(counter))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de Tweets : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJaVJlMErc6"
      },
      "source": [
        "## Extrayendo Tweets exactos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_NWRjasEp-U"
      },
      "source": [
        "max_resultados = None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vRqkWAE86E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fb559c-7b97-4ab2-8a64-9dd3247e1da6"
      },
      "source": [
        "tweets_extraidos = \"snscrape --format '{content!r}'\"+ f\" --max-results {max_resultados} --since {fecha_inicial} twitter-search '{termino_busqueda} until:{fecha_final}' > extracted-tweets.txt\"\n",
        "os.system(tweets_extraidos)\n",
        "if os.stat(\"extracted-tweets.txt\").st_size == 0:\n",
        "  print('No Tweets found')\n",
        "else:\n",
        "  df = pd.read_csv('extracted-tweets.txt', names=['content'])\n",
        "  for row in df['content'].iteritems():\n",
        "    print(row)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Tweets found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe9pHitWFJR6"
      },
      "source": [
        "## Extrayendo los Tweets por usuarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvOrIX75FIDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c04cf0-95c9-498a-e3b4-24e325920949"
      },
      "source": [
        "nombre_usuario = None\n",
        "user_tweets = \"snscrape --format '{content!r}'\"+ f\" --max-results {max_resultados} --since {fecha_inicial} twitter-user '{nombre_usuario} until:{fecha_final}' > user-tweets.txt\"\n",
        "os.system(user_tweets)\n",
        "if os.stat(\"user-tweets.txt\").st_size == 0:\n",
        "  print('No se encontraron Tweets')\n",
        "else:\n",
        "  df = pd.read_csv('user-tweets.txt', names=['content'])\n",
        "  for row in df['content'].iteritems():\n",
        "    print(row)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron Tweets\n"
          ]
        }
      ]
    }
  ]
}