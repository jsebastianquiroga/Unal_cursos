{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping - Twitter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgq0fOWYFKux"
      },
      "source": [
        "# Web Scraping in Social Media con Python\n",
        "\n",
        "En esta sesión se abordará el web scraping para una de las redes sociales con mayor tendencia a nivel mundial: Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzQr7j1cFb-5"
      },
      "source": [
        "### Instalación e importación de paquetes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTG0CjisEWGv"
      },
      "source": [
        "!pip install -q snscrape"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upELTM7FEW52"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import date"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4CjmLVnFpLJ"
      },
      "source": [
        "### Variables\n",
        "Se establecen las variables a partir de las cuales se realizará el web scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRI_zQ1sEYaU"
      },
      "source": [
        "hoy = date.today()\n",
        "fecha_final = hoy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omLTd2slEbn7"
      },
      "source": [
        "termino_busqueda = None\n",
        "fecha_inicial = None"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYfif5q9Ek_S"
      },
      "source": [
        "## Número total de Tweets por términos buscados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6vi7EuFEdVv"
      },
      "source": [
        "os.system(f\"snscrape --since {fecha_inicial} twitter-search '{termino_busqueda} until:{fecha_final}' > result-tweets.txt\")\n",
        "if os.stat(\"result-tweets.txt\").st_size == 0:\n",
        "  counter = 0\n",
        "else:\n",
        "  df = pd.read_csv('result-tweets.txt', names=['link'])\n",
        "  counter = df.size\n",
        "\n",
        "print('Número de Tweets : '+ str(counter))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsJaVJlMErc6"
      },
      "source": [
        "## Extrayendo Tweets exactos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_NWRjasEp-U"
      },
      "source": [
        "max_resultados = None"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vRqkWAE86E"
      },
      "source": [
        "tweets_extraidos = \"snscrape --format '{content!r}'\"+ f\" --max-results {max_resultados} --since {fecha_inicial} twitter-search '{termino_busqueda} until:{fecha_final}' > extracted-tweets.txt\"\n",
        "os.system(tweets_extraidos)\n",
        "if os.stat(\"extracted-tweets.txt\").st_size == 0:\n",
        "  print('No Tweets found')\n",
        "else:\n",
        "  df = pd.read_csv('extracted-tweets.txt', names=['content'])\n",
        "  for row in df['content'].iteritems():\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe9pHitWFJR6"
      },
      "source": [
        "## Extrayendo los Tweets por usuarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvOrIX75FIDK"
      },
      "source": [
        "nombre_usuario = None\n",
        "user_tweets = \"snscrape --format '{content!r}'\"+ f\" --max-results {max_resultados} --since {fecha_inicial} twitter-user '{nombre_usuario} until:{fecha_final}' > user-tweets.txt\"\n",
        "os.system(user_tweets)\n",
        "if os.stat(\"user-tweets.txt\").st_size == 0:\n",
        "  print('No se encontraron Tweets')\n",
        "else:\n",
        "  df = pd.read_csv('user-tweets.txt', names=['content'])\n",
        "  for row in df['content'].iteritems():\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}